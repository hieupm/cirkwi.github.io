---
published: true
title: "Apache Kafka Series - Learn Apache Kafka for Beginners"
excerpt: "Apache Kafka Series - Learn Apache Kafka for Beginners"
toc: true
toc_sticky: true
toc_label: "Apache Kafka Series - Learn Apache Kafka for Beginners"
toc_icon: "terminal"
author_profile: false
comments: true
header:
  overlay_image: "assets/images/covers/cover-cloud.jpg"
  overlay_filter: 0.2
  teaser: "assets/images/covers/cover-cloud.jpg"
categories: [streaming, kafka, java]
---

Course: Apache Kafka Series - Learn Apache Kafka for Beginners
Ref: https://www.udemy.com/course/apache-kafka/

# Why Apache Kafka


# Topics, Partitions and Offsets
- **Topics**: a particular stream of data. A topic is identified by its name. 
- Topics are split in **partitions**
    - Need to specify "how many" partitions while creating a topic, this number can be changed later. 
    - Each partition is ordered 
    - Each message within a partition gets an incremetal id, called **offset**. It's infinite and unbounded.  
    - Messages are ordered within the partition but not across other partitions
- Data is kept only for a limited time (default is one week)
- Once the data is written to a partition, it can't be changed  (**immutability**)
- Data is sent randomly over partitiions if key is not provided

# Brocker and Topics
- A Kafka cluster is composed of multiple brokers (servers)
- Each broker is identified with its ID (integer)
- Each broker contains certain topic partitions
- After connecting to any broker (called a bootstrap broker), you will be connected to the entire cluster. 
    - A good number to get started is 3 brokers. 
- Partitions are distributed across all the brokers by Kafka. 

# Topic Replication
- Topic replication factor must be defined at the creation of topic. 
- Topics should have a replication factor > 1 (usually between 2 and 3). 
- If a broker is down, another broker can serve the data. 
- At any time, only ONE broker can be a **leader** for a given partition. 
    - Only the leader can receive data for a partition. 
- The other brokers will synchronize the data. 
    - Each partition has one leader and multiple ISR (in-sync replica)
- Zookeeper decides leaders and ISR in cluster. 
    - the re-election will be executed when the leader comes down. 
    - the leader is re-elected when it comes back. 

# Producers and Message Keys
- Producers write data to topics (which is made of partitions)
- Producers automatically know to which broker and partition to write to
- In case of Broker failures, Producers will automatically recover
- The load is balanced to many brokers hosting the number of partitions.
    - if data is sent without a key, it will be sent round robin across the brokers
- Producers can choose to receive acknowledgment of data writes

# Consummers & Consumer Groups
- Consumers read data from a topic (identified by name)
- Consumers know which broker to read from
  - Consumers can also read from multiple partitions
- In case of broker failures, consumers know how to recover
- Data is read in order **within each partition**
  - In case of reading from multiple partitions, there is no gurantee about the order betwen partitions. The consumer read data in parallel. 
- Consumers read data in **consumer groups**
- Each consumer within a group reads from exclusive partitions
  - if you have more consumers than partitions, some consumers will be inactive. 
    - the inactive consumer become active in case of failure/crash of other consumer in the same group. 
  - a **GroupCoordiantor** and a **ConsumerCoordiantor** are automatically used to assign a consumer to a partition. It's a mechanism already implemented in Kafka. 

# Consumer Offsets & Delivery Semantics
- Kafka stores the offsets at which a consumer group has been reading (like checkpointing or bookmarking)
- The offsets committed live in a Kafka topic named **__consumer_offsets**
- When a consumer in a group has processed data received from Kafka, it should be committing the offsets. It's an action (done automatically for you) of writing through the topic named __consumer_offsets. 
- If a consumer (group) dies, it will be able to read back from where it left off thanks to the committed consumer offsets. 
- **Delivery semantics** for consumers: consumers choose when to commit offsets. There are 3 delivery semantics: 
  - **At most once**: offsets are committed as soon as the message is received. If the processing goes wrong, the message will be **lost** (it won't be read again). 
  - **At least once**: Offsets are committed after the message is processed. If the processing goes wrong, the message will be read again. This can result in duplicate processing of messages. Make sur your processing is *idempotent* (i.e. processing again the messages won't impact your systems)
  - **Exactly once**: Can be achived for Kafka to Kafka workflows using Kafka Streams API. 
    - For Kafka to External System Workflows, use an idempotent consumer to make sure there's no duplicates in the final database. 

# Kafka Broker Discovery
- Every Kafka broker is also called a "bootstrap server"
  - That means that you only need to connect to one broker, and you will be connected to the entire cluster. 
- Each broker knows about all brokers, topics and partitions (metatdata)

	![dstream-1]({{ site.url }}{{ site.baseurl }}/assets/images/kafka-mooc/Kafka-Broker-Discovery-1.PNG "Kafka Broker Discovery"){: .align-center}

# Zookeeper

# Kafka Guarantee

# Theory Roundup