---
published: true
title: "Apache Kafka Series - Learn Apache Kafka for Beginners"
excerpt: "Apache Kafka Series - Learn Apache Kafka for Beginners"
toc: true
toc_sticky: true
toc_label: "Apache Kafka Series - Learn Apache Kafka for Beginners"
toc_icon: "terminal"
author_profile: false
comments: true
header:
  overlay_image: "assets/images/covers/cover-cloud.jpg"
  overlay_filter: 0.2
  teaser: "assets/images/covers/cover-cloud.jpg"
categories: [streaming, kafka, java]
---

Course: Apache Kafka Series - Learn Apache Kafka for Beginners
Ref: https://www.udemy.com/course/apache-kafka/

# Why Apache Kafka


# Topics, Partitions and Offsets
- **Topics**: a particular stream of data. A topic is identified by its name. 
- Topics are split in **partitions**
    - Need to specify "how many" partitions while creating a topic, this number can be changed later. 
    - Each partition is ordered 
    - Each message within a partition gets an incremetal id, called **offset**. It's infinite and unbounded.  
    - Messages are ordered within the partition but not across other partitions
- Data is kept only for a limited time (default is one week)
- Once the data is written to a partition, it can't be changed  (**immutability**)
- Data is sent randomly over partitiions if key is not provided

# Brocker and Topics
- A Kafka cluster is composed of multiple brokers (servers)
- Each broker is identified with its ID (integer)
- Each broker contains certain topic partitions
- After connecting to any broker (called a bootstrap broker), you will be connected to the entire cluster. 
    - A good number to get started is 3 brokers. 
- Partitions are distributed across all the brokers by Kafka. 

# Topic Replication
- Topic replication factor must be defined at the creation of topic. 
- Topics should have a replication factor > 1 (usually between 2 and 3). 
- If a broker is down, another broker can serve the data. 
- At any time, only ONE broker can be a **leader** for a given partition. 
    - Only the leader can receive data for a partition. 
- The other brokers will synchronize the data. 
    - Each partition has one leader and multiple ISR (in-sync replica)
- Zookeeper decides leaders and ISR in cluster. 
    - the re-election will be executed when the leader comes down. 
    - the leader is re-elected when it comes back. 

# Producers and Message Keys
- Producers write data to topics (which is made of partitions)
- Producers automatically know to which broker and partition to write to
- In case of Broker failures, Producers will automatically recover
- The load is balanced to many brokers hosting the number of partitions.
    - if data is sent without a key, it will be sent round robin across the brokers
- Producers can choose to receive acknowledgment of data writes

# Consummers & Consumer Groups
- Consumers read data from a topic (identified by name)
- Consumers know which broker to read from
  - Consumers can also read from multiple partitions
- In case of broker failures, consumers know how to recover
- Data is read in order **within each partition**
  - In case of reading from multiple partitions, there is no gurantee about the order betwen partitions. The consumer read data in parallel. 
- Consumers read data in **consumer groups**
- Each consumer within a group reads from exclusive partitions
  - if you have more consumers than partitions, some consumers will be inactive. 
    - the inactive consumer become active in case of failure/crash of other consumer in the same group. 
  - a **GroupCoordiantor** and a **ConsumerCoordiantor** are automatically used to assign a consumer to a partition. It's a mechanism already implemented in Kafka. 

# Consumer Offsets & Delivery Semantics
- Kafka stores the offsets at which a consumer group has been reading (like checkpointing or bookmarking)
- The offsets committed live in a Kafka topic named **__consumer_offsets**
- When a consumer in a group has processed data received from Kafka, it should be committing the offsets. It's an action (done automatically for you) of writing through the topic named __consumer_offsets. 
- If a consumer (group) dies, it will be able to read back from where it left off thanks to the committed consumer offsets. 
- **Delivery semantics** for consumers: consumers choose when to commit offsets. There are 3 delivery semantics: 
  - **At most once**: offsets are committed as soon as the message is received. If the processing goes wrong, the message will be **lost** (it won't be read again). 
  - **At least once**: Offsets are committed after the message is processed. If the processing goes wrong, the message will be read again. This can result in duplicate processing of messages. Make sur your processing is *idempotent* (i.e. processing again the messages won't impact your systems)
  - **Exactly once**: Can be achived for Kafka to Kafka workflows using Kafka Streams API. 
    - For Kafka to External System Workflows, use an idempotent consumer to make sure there's no duplicates in the final database. 

# Kafka Broker Discovery
- Every Kafka broker is also called a "bootstrap server"
  - That means that **you only need to connect to one broker**, and you will be connected to the entire cluster. 
- Each broker knows about all brokers, topics and partitions (metatdata)
- The mechanism is already implemented in Kafka. 

	![dstream-1]({{ site.url }}{{ site.baseurl }}/assets/images/kafka-mooc/Kafka-Broker-Discovery-1.PNG "Kafka Broker Discovery"){: .align-center}

# Zookeeper
- Zookeeper manages brokers (keeps a list of them)
- Zookeeper helps in performing leader election for partitions. 
- Zookeeper sends notifications to Kafka in case of changes (new topic, broker dies, broker comes up, delete topics,...)
- Kafka can't work without Zookeper
- Zookeeper by design operates with an odd number of servers (brokers). 
- Zookeeper has a leader (handle writes) the rest of the servers are followers (handle reads) **(?)**
- Zookeeper is completely isolated from the consumers

# Kafka Guarantee
- Messages are appended to a topic-partition in the oder they are sent
- Consumers read messages in the order stored in a topic-partition
- With a replication factor of N, producers and consumers can tolerate up to N-1 brokers being down. 
- Replication factor of 3 is a good idea:
  - Allows for one broker to be taken down for maintenance
  - Allows for another broker to be taken down unexpectedly
- As long as the number of partitions remains constant for a topic (no new partitions), the same key will always go to the same partition. 

# Get started with Kafka
- Check if java version is java 8
  - In case not, you have to upgrade your java version to 8
    ```
    # Install brew if needed:
    /usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
    // install java 8 using brew
    brew tap caskroom/versions
    brew cask install java8
    ```
- Download Kafka lastest version from https://kafka.apache.org/downloads 
  ```
  // Move tar file to install folder 
  mv /Users/minh-hieu.pham/Download/kafka_2.12-2.2.0.tar /Users/minh-hieu.pham/Documents/install
  // Unzip file
  tar -xvf kafka_2.12-2.2.0.tar
  ```
- Add Kafka directory to bash_profile file
  ```
  export PATH="$PATH:/Users/minh-hieu.pham/Documents/install/kafka_2.12-2.2.0/bin"
  ```
  - "source" after modify bash_profile file
    ```
    source ~/.bash_profile
    ```
- Make Zookeeper data directory
  ```
  mkdir data
  mkdir data/zookeeper

  # Edit config/zookeeper.properties
  # change line to 
  # dataDir=/your/path/to/data/zookeeper
  dataDir=/Users/minh-hieu.pham/Documents/install/kafka_2.12-2.2.0/data/zookeeper
  ```
- Start Zookeeper
  ```
  zookeeper-server-start.sh [kafka installed directory]/config/zookeeper.properties
  ```
  - Zookeeper will be started at *0.0.0.0:2181*
- Open the second terminal window and make the Kafka data directory
  ```
  # create Kafka data directory
  mkdir data/kafka
  # Edit config/server.properties
  # change line to 
  # log.dirs=/your/path/to/data/kafka
  log.dirs=/Users/minh-hieu.pham/Documents/install/kafka_2.12-2.2.0/data/kafka
  ```
- Start Kafka
  ```
  kafka-server-start.sh [kafka installed directory]/config/server.properties
  ```
- In the data directory of Kafka:
  ```
  ```

# Kafka - CLI (Command Line Interface)

- Create a topic
 
  ```
  kafka-topics.sh --zookeeper 127.0.0.1:2181 \
  --create \
  --topic first_topic \
  --partitions 3 \
  --replication-factor 1
  ```
  - In Kafka, you cannot create a topic with replication factor greater than the number of brokers you have.
- Topic operations
  ```bash
  # kafka-topics.sh --zookeeper 127.0.0.1:2181 --list 
  # kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic first_topic --describe
  Topic:first_topic       PartitionCount:3        ReplicationFactor:1     Configs:
        Topic: first_topic      Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: first_topic      Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: first_topic      Partition: 2    Leader: 0       Replicas: 0     Isr: 0
  # kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --delete
  ```

## Kafka Consoles Producer CLI
- Producing
  ```bash
  #kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic
    >Hello
    >Bonjour 
    >Je m'appelle Minh-Hieu PHAM
    >juste un autre message 
    >
  ```
- Producing with properties
  ```
  #kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic --producer-property acks=all
  ```
- If you send message to a topic not exist yet, you get the warning:
  ```
  [2019-05-08 15:54:53,508] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 3 : {new_topic=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
  ```
  - The topic gets created with default properties (partition 1, replication factor 1,...) but there was no leader election that happened yet, so you get this exception LEADER_NOT_AVAILABLE. 
  - The producer just tried and waited until the leader was available, and it produced another message. 
  - You can change the default properties by editing the *config/server.properties*
    ```
    num.partitions=3
    ```
## Kafka Consoles Producer CLI
- Consuming from a topic: 
  ```bash
  kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic
  ```
  - By default, a consumer only reads from that point when you launch it and will only intercept the new message. 
- Consuming from beginning of the topic:
  ```bash
  kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning
  ```
  - The order of messages in this consumer is not "total", the order is per partition. The "first_topic" was created with 3 partitions. 

## Kafka Consumers in Group
- The consumer groups rebalanced and shared the load between consumers. 
```
# start one consumer
kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --group my-first-application --from-beginning

# start one producer and start producing
kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic first_topic

# start another consumer part of the same group. See messages being spread
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --group my-first-application
```
- When a consumer in group went down, the new partitions have been reassigned to another consumer available in group. 
- When the group is specified, the offsets will be committed in Kafka.
- Some Kafka consumer groups operations
```bash
# list consumer groups
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list
 
# describe one specific group
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-second-application

# describe another group
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-first-application
#Consumer group 'my-first-application' has no active members.

#TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
#first_topic     0          2               2               0               -               -               -
#first_topic     1          1               1               0               -               -               -
#first_topic     2          1               1               0               -               -               -

# start a consumer in another terminal
kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --group my-first-application

# describe the group now
kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-first-application
#TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID
#first_topic     0          2               2               0               consumer-1-2868a5d6-9dd7-4c37-b7d9-67818eafd298 /192.168.0.18   consumer-1
#first_topic     1          1               1               0               consumer-1-2868a5d6-9dd7-4c37-b7d9-67818eafd298 /192.168.0.18   consumer-1
#first_topic     2          1               1               0               consumer-1-2868a5d6-9dd7-4c37-b7d9-67818eafd298 /192.168.0.18   consumer-1
``` 
- Reset the offset of a consumer group
    - Assignments can only be reset if the group 'my-first-application' is inactive. You need to desactivate all consumers in group befor assignment. 
    ```bash
    kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-first-application --reset-offsets --to-earliest --execute --topic first_topic
    #TOPIC                          PARTITION  NEW-OFFSET     
    #first_topic                    0          0              
    #first_topic                    2          0              
    #first_topic                    1          0  
    # describe the group again
    kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-first-application
    #TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
    #first_topic     0          0               2               2               -               -               -
    #first_topic     1          0               1               1               -               -               -
    #first_topic     2          0               1               1               -               -               -
    ```
    - Shift forward and backward 
    ```bash
    # shift offsets by 2 (forward) as another strategy
    kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-first-application --reset-offsets --shift-by 1 --execute --topic first_topic

    # shift offsets by 2 (backward) as another strategy
    kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-first-application --reset-offsets --shift-by -1 --execute --topic first_topic
    ```