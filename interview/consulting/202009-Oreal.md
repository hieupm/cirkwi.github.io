### Client: Oreal
### Portage: Margo Consulting
#### Contact: Raphaël (Margo)
### Planning
- Entretien: 18h-19h (15/09/2020) - Attente de confirmation
### Contexte
```
La mission proposée est au sein de l'équipe DATAHUB.
La plateforme DATAHUB a pour role:
- Centralisation les données utilisées au sein de l'entité BNP AM
- Fournisseur des services permettant d'exploiter ces données
En terme d'environnement technique, la plateforme DATAHUB est portée par une distribution MapR et la majorité des développements effectués par l'équipe DATAHUB sont en python.
Le coeur du DATAHUB comprend:
- l'intégration de fichier brut sur le cluster MapR
- la structuration de ces données (provider Scaled Risk/ techno sous jacente HBASE)
- l'exposition de ces données via ODBC, HTTP
```
### Mission
```
**Livrable**
```

### Pre-requises
```
```

## Préparation

### Présentation
```
Après avoir réalisé un parcours technique et fonctionnel en parallèle sur les problématiques des systèmes d’information à large échelle, j’ai démarré ma carrière en tant Data Ingénieur puis Concepteur Applicatif.

Mes connaissances se focalisent sur les sujets de l’ingénierie, l’analyse et la gouvernance des données. Je m’intéresse également de me challenger par des problématiques de l’urbanisation applicative autour de la data.

J’ai terminé récemment ma mission chez Renault en tant Concepteur Applicatif pour l’ensemble des sujets data au seine d’une équipe transverse de la DSI du groupe Renault. Nos challenges sont à la fois consolider les données venant de plusieurs sources en fournissant les informations de bon format technique/fonctionnel aux projets consommateurs. Mon rôle en tant concepteur applicatif s’est résumé en trois points :

	• Premièrement, le rôle data ingénieur de concevoir et gérer la réalisation des pipelines de données tout en collaborant avec les intervenants sources et les applications consommatrices.

	• Deuxièmement, le rôle concepteur applicatif qui traite des sujets de l’urbanisation des applications et la gouvernance de données ; 

	• Troisièmement, le rôle animateur qui coordonne les mises en production/ migration/ développement et aussi le passage de connaissance des projets réalisés par l’équipe en France vers l’équipe en Inde ; 

Les technologies utilisées sont principalement basées sur le stack Hadoop (distribution Hortonwork) notamment Spark/Scala, Oozie, Hive, Elasticsearch, Oracle. On a eu aussi des sujets Data sur GCP, notamment l'ingénierie et l'analyse de données comme mettre en place des process ETL, structurer la modélisation de données dans BigQuery, optimiser les requêtages et visualiser des données sous Data Studio. J'en ai profité pour me former les différentes technologies de cloud et réalisé le certifcat Data Ingénieur GCP. L'idée est d'être de plus en plus polyalent pour la manipulation de données.    
```

### Vos ambitions
```
Mes ambitions se résument sur deux points: 
- Diversifier mes compétences techniques en travaillant sur différents contextes projets; 
- Elargir mes connaissances métiers particulièrement dans le secteur de la finance; 
```

### GCP chez Renault
```
- Context: On travaille actullement sur une plate-forme on-premisse Hadoop, on rencontre des difficultés scalabiliser des différents cas d'usage. On a décidé d'adopter la culture d'architecture de cloud pour différentes raisons. 
- Réalisation: 
	- Projet de migration 
	- Projet from scatch
```

### Question à poser
- Structuration des sujets data par rapport l'existant: réception de données, data management/gouvernance,... 
- Les données traitées et les livrables des réalisations 
- Les attentes 